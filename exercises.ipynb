{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1732181925083,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "NZLKEFGqpkza"
   },
   "outputs": [],
   "source": [
    "from random import randint, choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7kMDITdMpkzc"
   },
   "source": [
    "# Map Reduce\n",
    "\n",
    "In the part of the assignment you are requested to use Map Reduce paradigm to solve the following exercises.\n",
    "\n",
    "**NOTE THAT**: **A solution that does not use map reduce is not valid!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UvFKq5Dpkzd"
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "You have a list of dictionaries, each representing a student with the following properties: a name and an array of test scores. Your task is to use map, filter, and reduce to calculate the average test score for each student, and then return a list of dictionaries containing only the students whose average score is above 90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XnZxeOdtpkze"
   },
   "outputs": [],
   "source": [
    "students = [\n",
    "    {\"name\": \"Alice\", \"scores\": [95, 92, 88, 100]},\n",
    "    {\"name\": \"Bob\", \"scores\": [78, 81, 85, 80]},\n",
    "    {\"name\": \"Charlie\", \"scores\": [99, 91, 94, 96]},\n",
    "    {\"name\": \"Diana\", \"scores\": [85, 87, 89, 83]}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WopOVxHSpkzf"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGYCqweYpkzf",
    "outputId": "89230ab4-a15a-4ae5-84a3-9eb13573a4a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Alice', 'average_score': 93.75},\n",
       " {'name': 'Charlie', 'average_score': 95.0}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"name\": \"Alice\", \"average_score\": 93.75},\n",
    "    {\"name\": \"Charlie\", \"average_score\": 95.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TG5h3pN1pkzg"
   },
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 285,
     "status": "ok",
     "timestamp": 1732181928585,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "3ZB3sFT_pkzh",
    "outputId": "cf486e14-4d6f-455d-8f69-19096dfe9831"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Student 1', 'scores': [69, 50, 98, 54]},\n",
       " {'name': 'Student 2', 'scores': [69, 74, 71]},\n",
       " {'name': 'Student 3', 'scores': [89, 60, 88, 56, 63]}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_student_dataset(num_students=50):\n",
    "    names = [f\"Student {i}\" for i in range(1, num_students + 1)]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": name,\n",
    "            \"scores\": [randint(50, 100) for _ in range(randint(3, 6))]  # Random scores between 50 and 100\n",
    "        }\n",
    "        for name in names\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_student_dataset = generate_random_student_dataset(50)\n",
    "random_student_dataset[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MHi3FLeWpkzi"
   },
   "outputs": [],
   "source": [
    "# your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWL_3xWNpkzj"
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "You have a list of dictionaries, each representing a product with the following properties: name, price, and category. Using the functions `map`, `filter`, and `reduce`, calculate the average price of the products in each category and return a list of dictionaries containing only the categories where the average price exceeds 50.\n",
    "\n",
    "Example input:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wwk7f8Ihpkzk"
   },
   "outputs": [],
   "source": [
    "products = [\n",
    "    {\"name\": \"Product A\", \"price\": 60, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product B\", \"price\": 40, \"category\": \"Electronics\"},\n",
    "    {\"name\": \"Product C\", \"price\": 70, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product D\", \"price\": 30, \"category\": \"Home\"},\n",
    "    {\"name\": \"Product E\", \"price\": 90, \"category\": \"Sports\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Agz3cP7Ppkzl"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LbFtUV_apkzl",
    "outputId": "745cdcbe-7320-4a08-de7b-0e1bcb84473e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'category': 'Electronics', 'average_price': 50.0},\n",
       " {'category': 'Sports', 'average_price': 90.0}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"category\": \"Electronics\", \"average_price\": 50.0},\n",
    "    {\"category\": \"Sports\", \"average_price\": 90.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nKBEAQE3pkzl"
   },
   "source": [
    "### Test\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 284,
     "status": "ok",
     "timestamp": 1732181933353,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "0qj_9nZSpkzm",
    "outputId": "7bab35c7-84d0-4603-a1da-dc4a76768179"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Product 1', 'price': 112, 'category': 'Home'},\n",
       " {'name': 'Product 2', 'price': 139, 'category': 'Clothing'},\n",
       " {'name': 'Product 3', 'price': 168, 'category': 'Electronics'},\n",
       " {'name': 'Product 4', 'price': 137, 'category': 'Books'},\n",
       " {'name': 'Product 5', 'price': 97, 'category': 'Clothing'}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_product_dataset(num_products=100):\n",
    "    categories = [\"Electronics\", \"Home\", \"Sports\", \"Books\", \"Clothing\", \"Toys\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Product {i}\",\n",
    "            \"price\": randint(10, 200),  # Random price between 10 and 200\n",
    "            \"category\": choice(categories),  # Randomly choose a category\n",
    "        }\n",
    "        for i in range(1, num_products + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "# Example of using the function\n",
    "random_dataset = generate_random_product_dataset(100)\n",
    "random_dataset[:5]  # Display the first 5 entries to check the dataset structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AG9V3Wt7pkzm"
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "# hints: 1) Group products by category (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average price for each category and filter categories with an average price > 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hivtZEf7pkzm"
   },
   "source": [
    "# Exercise 3\n",
    "\n",
    "You have a list of dictionaries, each representing an employee with the following properties: name, salary, and department. Your task is to use `map`, `filter`, and `reduce` to calculate the average salary for each department and return a list of dictionaries containing only the departments where the average salary is above 65,000.\n",
    "\n",
    "**Example Input**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1732181936402,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "N8vjLRHxpkzm"
   },
   "outputs": [],
   "source": [
    "employees = [\n",
    "    {\"name\": \"John\", \"salary\": 70000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Jane\", \"salary\": 75000, \"department\": \"Engineering\"},\n",
    "    {\"name\": \"Alice\", \"salary\": 60000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Bob\", \"salary\": 68000, \"department\": \"HR\"},\n",
    "    {\"name\": \"Charlie\", \"salary\": 90000, \"department\": \"Marketing\"},\n",
    "    {\"name\": \"Diana\", \"salary\": 50000, \"department\": \"Marketing\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "otSniMO7pkzm"
   },
   "source": [
    "Use `map`, `reduce` and `filter` that produce an output like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Kx4HT8RXpkzn",
    "outputId": "8653ff13-815d-4040-c68e-fc4a6825134d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'department': 'Engineering', 'average_salary': 72500.0},\n",
       " {'department': 'Marketing', 'average_salary': 70000.0}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\n",
    "    {\"department\": \"Engineering\", \"average_salary\": 72500.0},\n",
    "    {\"department\": \"Marketing\", \"average_salary\": 70000.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GD_xlB78pkzn"
   },
   "source": [
    "### Test\n",
    "\n",
    "Test your solution using the dataset generated by the following function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 508,
     "status": "ok",
     "timestamp": 1732181939215,
     "user": {
      "displayName": "Marco Zecchini",
      "userId": "04080461015443912025"
     },
     "user_tz": -60
    },
    "id": "RhR9JLK-pkzn",
    "outputId": "72bc934d-4d3c-477e-cf84-3cf1d8fae61a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Employee 1', 'salary': 40737, 'department': 'Engineering'},\n",
       " {'name': 'Employee 2', 'salary': 77275, 'department': 'Engineering'},\n",
       " {'name': 'Employee 3', 'salary': 107774, 'department': 'IT'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_random_employee_dataset(num_employees=50):\n",
    "    departments = [\"Engineering\", \"HR\", \"Marketing\", \"Sales\", \"Finance\", \"IT\"]\n",
    "    dataset = [\n",
    "        {\n",
    "            \"name\": f\"Employee {i}\",\n",
    "            \"salary\": randint(40000, 120000),  # Random salary between 40,000 and 120,000\n",
    "            \"department\": choice(departments)  # Randomly choose a department\n",
    "        }\n",
    "        for i in range(1, num_employees + 1)\n",
    "    ]\n",
    "    return dataset\n",
    "\n",
    "random_employee_dataset = generate_random_employee_dataset(50)\n",
    "\n",
    "random_employee_dataset[:3]  # Display the first 3 entries of each dataset for checking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pt9m6NK-pkzo"
   },
   "outputs": [],
   "source": [
    "# your code goes here\n",
    "# hints: 1) Group employees' salaries by department (you don't need to use map reduce for this part), then 2) use map reduce paradigm to\n",
    "# calculate the average salary for each department and filter departments with an average salary > threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bzxr0v2Rpkzo"
   },
   "source": [
    "# Biopython\n",
    "\n",
    "Write the following five functions to analyze global alignments between two sequences using Biopython's `pairwise2` module:\n",
    "\n",
    "1. **countMatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment (pairwise2.globalxx) of the same length. It returns the number of positions where the elements of both sequences match.\n",
    "\n",
    "2. **countMismatches(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of positions where the elements of the two sequences are different (i.e., they are not gaps, and the characters do not match).\n",
    "\n",
    "3. **countGapOpens(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap openings in the alignment (a gap is opened when a '-' appears in the sequence).\n",
    "\n",
    "4. **countGapExtensions(s1, s2)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment of the same length. It returns the number of gap extensions (where '-' continues in the alignment after an initial gap is opened).\n",
    "\n",
    "5. **getScore(s1, s2, matchScore, mismatchPenalty, gapOpenPenalty, gapExtensionPenalty)**  \n",
    "   This function takes two sequences (`s1`, `s2`) aligned using global alignment and returns the alignment score based on the provided scoring scheme: `matchScore` for matches, `mismatchPenalty` for mismatches, `gapOpenPenalty` for opening a gap, and `gapExtensionPenalty` for extending a gap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5PIaf6BUpkzo"
   },
   "outputs": [],
   "source": [
    "# Add your functions here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81O19v1fpkzo"
   },
   "source": [
    "### Test\n",
    "Align the sequences of the [Interleukin-12](https://en.wikipedia.org/wiki/Interleukin_12) chain A (denoted as `s1`) from the file [`IL12A.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12A.fasta) and the Interleukin-12 chain B (denoted as `s2`) from the file [`IL12B.fasta`](https://qcbsciprolab2020.readthedocs.io/en/latest/file_samples/IL12B.fasta) and check the score as computed from pairwise2 and from your functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZBhfr3jepkzp"
   },
   "outputs": [],
   "source": [
    "# add the output of the test here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lgis \n",
    "'''\n",
    "A solution to a ROSALIND bioinformatics problem.\n",
    "\n",
    "Problem Title: Longest Increasing Subsequence\n",
    "Rosalind ID: LGIS\n",
    "Rosalind #: 024\n",
    "URL: http://rosalind.info/problems/lgis/\n",
    "\n",
    "Goal - Provided a permutation sequence and should return the longest increasing\n",
    "and longest decreasing subsequences.\n",
    "\n",
    "I drew heavily from other people's code for this solution and therefore\n",
    "don't take much credit for its' implementation.  As such, there\n",
    "currently is not much novelty herein.  I created a brute-force method but\n",
    "it is extremely inefficient and would not have much use.  I have some potential\n",
    "other ideas but at the moment here is a very solid answer only slightly modified\n",
    "from other very talented programmers.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from math import ceil\n",
    "\n",
    "# Binary search to decrease time and computation\n",
    "def BS(S, data, value):\n",
    "    original_S = S\n",
    "    while len(S)>1:\n",
    "        # index is the exact middle if odd, and the lower value if even.\n",
    "        index = int(ceil(len(S)/2.0 - 1))\n",
    "        if data[S[index]] < value:\n",
    "            S = S[index+1:]\n",
    "        else:\n",
    "            S = S[:index+1]\n",
    "    return original_S.index(S[0])\n",
    "\n",
    "def LongestIncSubstring(data):\n",
    "    '''Returns an ordered list of the longest increasing substring.'''\n",
    "    S = [0]\n",
    "    parent = [None]*len(data)\n",
    "    for index in range(1,len(data)):\n",
    "        if data[index] > data[S[len(S)-1]]:\n",
    "            parent[index] = S[len(S)-1]\n",
    "            S.append(index)\n",
    "        else:\n",
    "            update_index = BS(S, data, data[index])\n",
    "            S[update_index] = index\n",
    "            parent[index] = S[update_index-1]\n",
    "\n",
    "    ''' Get the indicies of each element in the longest increasing\n",
    "        subsequence in reverse order.'''\n",
    "    LIS = [S[len(S)-1]]\n",
    "    for i in range(0,len(S)-1):\n",
    "        LIS.append(parent[LIS[len(LIS)-1]])\n",
    "\n",
    "    # Convert indicies to values and reverse.\n",
    "    LIS = [data[i] for i in LIS]\n",
    "    LIS.reverse()\n",
    "\n",
    "    return LIS\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    f =  open(\n",
    "        os.path.join(\n",
    "            os.path.split(\n",
    "                os.getcwd())[0],\n",
    "            \"data\", \"rosalind_lgis.txt\"),\n",
    "        'r')\n",
    "    \n",
    "    data = [map(int, line.rstrip().split()) for line in f.readlines()]\n",
    "    n = data.pop(0)\n",
    "    perm = data.pop(0)\n",
    "    f.close()\n",
    "\n",
    "    LIS = map(str, LongestIncSubstring(perm))\n",
    "\n",
    "    ''' The longest decreasing subsequence is equal to\n",
    "        LIS of -1*permutation.'''\n",
    "    negperm = [-1*i for i in perm]\n",
    "    LDS = map(str, [-1*i for i in LongestIncSubstring(negperm)])\n",
    "\n",
    "    outputhandle = open(\n",
    "        os.path.join(\n",
    "            os.path.split(\n",
    "                os.getcwd())[0],\n",
    "            \"output\", \"024_LGIS.txt\"),\n",
    "        'w')\n",
    "    outputhandle.write(' '.join(LIS) + '\\n')\n",
    "    outputhandle.write(' '.join(LDS))\n",
    "    outputhandle.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sseq\n",
    "'''\n",
    "\n",
    "Title: Finding a Spliced Motif\n",
    "Rosalind ID: SSEQ\n",
    "Rosalind #: 030\n",
    "URL: http://rosalind.info/problems/sseq\n",
    "\n",
    "Goal - Provided indicies of the nucleotides of a string t in string s.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from Bio import SeqIO\n",
    "\n",
    "f = open(\"data/rosalind_sseq.txt\", 'r')\n",
    "records = list(SeqIO.parse(f, \"fasta\"))\n",
    "f.close()\n",
    "\n",
    "s = str(records[0].seq)\n",
    "t = str(records[1].seq)\n",
    "\n",
    "indicies = []\n",
    "index = 0\n",
    "for nt in t:\n",
    "    s_temp = s[index:]\n",
    "    # get index of nucleotide, add prior index to keep position\n",
    "    index = s_temp.index(nt) + 1 + index\n",
    "    indicies.append(index)\n",
    "\n",
    "o = open(\"output/030_SSEQ.txt\", 'w')\n",
    "o.write(\" \".join(map(str, indicies)))\n",
    "o.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lcsq\n",
    "\n",
    "Title: Finding a Shared Spliced Motif\n",
    "Rosalind ID: LCSQ\n",
    "Rosalind #: 038\n",
    "URL: http://rosalind.info/problems/lcsq\n",
    "\n",
    "Goal to return the longest noncontinous subsequence of two strings.  This\n",
    "is essentially a longest subsequence problem.  I strongly suggest looking\n",
    "at the wikipedia page for longest common subsequence problem.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def LCSQ(seq1, seq2):\n",
    "    return backtrack(LCSQmatrix(seq1, seq2), seq1, seq2)\n",
    "\n",
    "\n",
    "def LCSQmatrix(seq1, seq2):\n",
    "    # create array of zeros\n",
    "    C = np.zeros((len(seq1)+1, len(seq2)+1), dtype=np.int)\n",
    "    for i in xrange(1, len(seq1)+1):\n",
    "        for j in xrange(1, len(seq2)+1):\n",
    "            # if elements in sequences match, add one to previous corner\n",
    "            if seq1[i-1] == seq2[j-1]:\n",
    "                C[i, j] = C[i-1, j-1] + 1\n",
    "            else:\n",
    "                # otherwise add maximum of two sides of corner\n",
    "                C[i, j] = max(C[i, j-1], C[i-1, j])\n",
    "    return C\n",
    "\n",
    "\n",
    "def backtrack(C, seq1, seq2):\n",
    "    # function to backtrack the sequence matrix\n",
    "    lcsq = ''\n",
    "    i, j = len(seq1), len(seq2)\n",
    "    # run until reach end of sequence\n",
    "    while i != 0 and j != 0:\n",
    "        # if the nt in sequences match, add to lcsq\n",
    "        if seq1[i-1] == seq2[j-1]:\n",
    "            lcsq = seq1[i-1] + lcsq\n",
    "            i -= 1\n",
    "            j -= 1\n",
    "        elif C[i, j] == C[i-1, j]:\n",
    "            # if not matching and count next lower is equal decrease i\n",
    "            # look at LCSQmatrix to understand the movement\n",
    "            i -= 1\n",
    "        else:\n",
    "            # if not matching and next lower not equal, decrease j\n",
    "            j -= 1\n",
    "    return lcsq\n",
    "\n",
    "\n",
    "\n",
    "def backtrack(C, seq1, seq2, i, j):\n",
    "    if i == 0 or j == 0:\n",
    "        return \"\"\n",
    "    if seq1[i-1] == seq2[j-1]:\n",
    "        return backtrack(C, seq1, seq2, i-1, j-1) + seq1[i-1]\n",
    "    else:\n",
    "        if C[i,j] == C[i-1, j]:\n",
    "            return backtrack(C, seq1, seq2, i-1, j)\n",
    "        else:\n",
    "            return backtrack(C, seq1, seq2, i, j-1)\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    from Bio import SeqIO\n",
    "\n",
    "    input_handle = \"/home/charles/Rosalind/data/rosalind_lcsq.txt\"\n",
    "    raw_data = list(SeqIO.parse(input_handle, 'fasta'))\n",
    "    sequences = []\n",
    "    for seq in raw_data:\n",
    "        sequences.append(str(seq.seq))\n",
    "\n",
    "    lcsq = LCSQ(sequences[0], sequences[1])\n",
    "    o = open(\"/home/charles/Rosalind/output/038_LCSQ.txt\", 'w')\n",
    "    o.write(lcsq)\n",
    "    o.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edit\n",
    "# http://rosalind.info/problems/edit/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    distance = {}\n",
    "    s = 'PLEASANTLY'\n",
    "    t = 'MEANLY'\n",
    "    \n",
    "    distance.update({((i, 0), i) for i in range(len(s) + 1)})\n",
    "    distance.update({((0, i), i) for i in range(len(t) + 1)})\n",
    "    \n",
    "    for i, j in product(range(1, len(s) + 1), range(1, len(t) + 1)):\n",
    "        if s[i - 1] == t[j - 1]:\n",
    "            cost = 0\n",
    "        else:\n",
    "            cost = 1\n",
    "            \n",
    "        distance[(i, j)] = min(distance[(i - 1, j - 1)] + cost, \n",
    "                               distance[(i - 1, j)] + 1, distance[(i, j - 1)] + 1)\n",
    "    \n",
    "    print distance[(i, j)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "edita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alignment(s,t):\n",
    "    matrix = {(i,j): ( j+i+2 , (max(i-1,-1),max(j-1,-1),(s[i] if i>=0 else '-') ,(t[j]) if j>=0 else '-') ) for i in range(-1,len(s)) for j in range(-1,len(t))}\n",
    "    matrix[-1,-1] = (0,(-1,-1,'',''))\n",
    "\n",
    "    [gap_symbol(matrix, i, j) for i in range(len(s)) for j in range(len(t))]\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def gap_symbol(matrix, i, j):\n",
    "        i_gap = (matrix[i - 1, j][0] + 1, (i - 1, j, s[i], \"-\") )\n",
    "        j_gap = (matrix[i, j - 1][0] + 1, (i, j - 1, \"-\", t[j]))\n",
    "        non_gap = (matrix[i - 1, j - 1][0] + int(s[i] != t[j]), (i - 1, j - 1, s[i], t[j]))\n",
    "        \n",
    "        matrix[i, j] = min(i_gap, j_gap, non_gap)\n",
    "\n",
    "def get_output(strings, s, t):\n",
    "    last = strings[len(s)-1,len(t)-1]\n",
    "    max_gap = last[0]\n",
    "    aug_s = [last[1][2]]\n",
    "    aug_t = [last[1][3]]\n",
    "    \n",
    "    while (last[1][2],last[1][3]) != ('',''):\n",
    "        last = strings[last[1][0],last[1][1]]\n",
    "        aug_s.append(last[1][2])\n",
    "        aug_t.append(last[1][3])\n",
    "    \n",
    "    return (max_gap, \"\".join(aug_s[::-1]), \"\".join(aug_t[::-1]))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    f = open(\"rosalind_edta.txt\")\n",
    "    s, t = [i.strip() for i in f.readlines()]\n",
    "    \n",
    "    strings = get_alignment(s,t)\n",
    "    distance, aug_s, aug_t = get_output(strings, s, t)\n",
    "    \n",
    "    print distance, '\\n', aug_s, '\\n ', aug_t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "glob\n",
    "# http://rosalind.info/problems/glob/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from itertools import product\n",
    "from Bio.SubsMat.MatrixInfo import blosum62\n",
    "\n",
    "def get_max_alignment(s, t):\n",
    "    sl, tl = len(s), len(t)\n",
    "    m = {(0, 0): (0, None)}\n",
    "    m.update({((i, 0), (i * - 5, (i - 1, 0))) for i in range(1, sl + 1)})\n",
    "    m.update({((0, i), (i * - 5, (0, i - 1))) for i in range(1, tl + 1)})\n",
    "    \n",
    "    for i, j in product(range(1, sl + 1), range(1, tl + 1)):\n",
    "        cost = blosum62.get((s[i - 1], t[j - 1]))\n",
    "        \n",
    "        if cost == None:\n",
    "            cost = blosum62.get((t[j - 1], s[i - 1]))\n",
    "        d = m[(i - 1, j - 1)][0] + cost\n",
    "        l = m[(i - 1, j)][0] - 5\n",
    "        u = m[(i, j - 1)][0] - 5\n",
    "        b = max(d, l, u)\n",
    "        \n",
    "        if d == b:\n",
    "            m[(i, j)] = (b, (i - 1, j - 1))\n",
    "        elif l == b:\n",
    "            m[(i, j)] = (b, (i - 1, j))\n",
    "        elif u == b:\n",
    "            m[(i, j)] = (b, (i, j - 1))\n",
    "            \n",
    "    return m[(i, j)][0]\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    results = []\n",
    "    protein_str = \"\"\n",
    "    \n",
    "    with open('rosalind_glob.txt') as fp:\n",
    "        for line in fp:\n",
    "            line = line.rstrip()\n",
    "        \n",
    "            if line.startswith(\">\"):\n",
    "                if(protein_str != \"\"):\n",
    "                    results.append(protein_str)\n",
    "                    protein_str = \"\"\n",
    "            else:\n",
    "                protein_str += line\n",
    "                \n",
    "    results.append(protein_str)\n",
    "    \n",
    "    print get_max_alignment(results[0], results[1])\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
